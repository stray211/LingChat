# 基础设置 BEGIN

## LLM 模型设置 BEGIN # 配置 LLM 和API相关的密钥和地址

LLM_PROVIDER="webllm" # 在这里选择对话模型，只可以填写webllm, gemini, ollama, lmstudio四个选项，webllm代表通用需要联网的AI模型（如deepseek），ollama和lmstudio表示本地，gemini如名）
CHAT_API_KEY="sk-114514" # DeepSeek 或其他聊天模型的 API Key
CHAT_BASE_URL="https://api.deepseek.com" # API的访问地址
MODEL_TYPE="deepseek-chat" # 使用的模型类型

OLLAMA_BASE_URL="http://localhost:11434" # Ollama配置- 地址
OLLAMA_MODEL="llama3" # Ollama配置- 模型

LMSTUDIO_MODEL_TYPE="unknown" # LM STUDIO 配置- 模型
LMSTUDIO_BASE_URL="http://localhost:1234/v1" # LM STUDIO 配置- 地址
LMSTUDIO_API_KEY="lm-studio" # LM STUDIO 配置- APIKEY 似乎不需要

GEMINI_API_KEY="sk-114514"
GEMINI_MODEL_TYPE="gemini-pro"
## LLM 模型设置 END

## 视觉模型设置 BEGIN # 配置 视觉模型 相关的密钥和地址
VD_API_KEY="sk-114514" # 图像识别模型的 API Key
VD_BASE_URL="https://api.siliconflow.cn/v1" # 视觉模型的API访问地址
VD_MODEL="Pro/Qwen/Qwen2.5-VL-7B-Instruct" # 视觉模型的模型类型
## 视觉模型设置 END

## 翻译设置 BEGIN # 配置 翻译相关的密钥和地址
TRANSLATE_LLM_PROVIDER="webllm" # 翻译模型提供者（同对话，推荐webllm）
TRANSLATE_API_KEY="" # 翻译模型的 API Key，推荐使用百炼平台的api_key
TRANSLATE_API_URL="https://dashscope.aliyuncs.com/compatible-mode/v1" # 翻译模型的api链接，推荐不要修改
TRANSLATE_MODEL="qwen3-30b-a3b-instruct-2507" # 翻译模型，推荐不要修改
## 翻译设置 END

## API 与 模型 设置 END

## 对话功能设定 BEGIN # 配置RAG（检索增强生成）系统，让AI能“记忆”历史对话
USE_RAG=false # 是否启用RAG系统 [type:bool]
USE_TIME_SENSE=true # 是否启用时间感知 [type:bool]
## 对话功能设定 END

# 基础设置 END


# 开发者设置 BEGIN

## RAG系统设定 BEGIN # 配置RAG（检索增强生成）系统，让AI能“记忆”历史对话
RAG_RETRIEVAL_COUNT=3 # 每次回答时检索的相关历史对话数量
RAG_WINDOW_COUNT=5 # 取当前的最新N条消息作为短期记忆，之后则是RAG消息，然后是过去的记忆。
RAG_HISTORY_PATH="ling_chat/data/rag_chat_history" # RAG历史记录存储路径
CHROMA_DB_PATH="ling_chat/data/chroma_db_store" # ChromaDB向量数据库的存储路径
RAG_CANDIDATE_MULTIPLIER=3 # RAG候选乘数，用于计算实际检索的文档数量
RAG_CONTEXT_M_BEFORE=2 # RAG检索时考虑当前消息之前的上下文数量
RAG_CONTEXT_N_AFTER=2 # RAG检索时考虑当前消息之后的上下文数量
RAG_PROMPT_PREFIX="--- 以下是根据你的历史记忆检索到的相关对话片段，请参考它们来回答当前问题。这些是历史信息，不是当前对话的一部分： ---" # RAG前缀提示，支持多行
RAG_PROMPT_SUFFIX="--- 以上是历史记忆检索到的内容。请注意，这些内容用于提供背景信息，你不需要直接回应它们，而是基于它们和下面的当前对话来生成回复。 ---" # RAG后缀提示，支持多行
## RAG系统设定 END

## 存储与日志 BEGIN # 配置日志和其他文件的存储位置
BACKEND_LOG_DIR="ling_chat/data/logs" # 后端服务日志目录
APP_LOG_DIR="ling_chat/data/log" # 应用行为日志目录
TEMP_VOICE_DIR="ling_chat/data/temp_voice" # 临时生成的语音文件存放目录
ENABLE_FILE_LOGGING=true # 是否将日志记录到文件
LOG_FILE_DIRECTORY="ling_chat/data/run_logs" # 日志文件的存储目录
CLEAN_TEMP_FILES=true # 是否在关闭后清理临时文件（包括语音等）
EMOTION_MODEL_PATH="ling_chat/third_party/emotion_model_18emo" # 情感分析模型路径
## 存储与日志 END

## Debug信息 BEGIN # 用于开发和调试的设置
LOG_LEVEL=INFO # 日志设置：默认为INFO，设置为DEBUG时启用开发者模式，输出更详尽的日志
PRINT_CONTEXT=true # 更改True/False，决定是否把本次发送给llm的全部上下文信息截取后打印到终端
## Debug信息 END

## 服务端口配置 BEGIN # 配置各个服务的网络监听地址和端口
BACKEND_BIND_ADDR="0.0.0.0" # 后端监听地址
BACKEND_PORT=8765 # 后端监听端口
FRONTEND_BIND_ADDR="0.0.0.0" # 前端监听地址
FRONTEND_PORT=3000 # 前端监听端口
EMOTION_BIND_ADDR="0.0.0.0" # 情感分析服务监听地址
EMOTION_PORT=8000 # 情感分析服务监听端口
## 服务端口配置 END

## 语音合成 BEGIN # 配置语音合成API KEY和本地地址等
SIMPLE_VITS_API_VITS_URL="http://localhost:23456/voice/vits" # SIMPLE_VITS_API(sva-vits)的语音合成API地址
STYLE_BERT_VITS2_URL="http://localhost:5000/voice" # Style-bert-vits2(sbv2)的语音合成API地址
SBV2API_API_URL="http://localhost:3000/synthesize" # Sbv2-Api(sbv2api)的语音合成API地址
SIMPLE_VITS_API_BERT_VITS2_URL="http://127.0.0.1:6006/voice/bert-vits2" # Bert-Vits2(sva-bv2)的语音合成API地址
GPT_SOVITS_API_URL="http://127.0.0.1:9880/tts" # GPT-SOVITS(gsv)的语音合成API地址
GPT_SOVITS_REF_AUDIO="" # GPT-SOVITS的参考音频路径
GPT_SOVITS_PROMPT_TEXT="" # GPT-SOVITS的参考音频文字版
AIVIS_API_KRY="" # AIVIS的API密钥
VOICE_FORMAT="wav" # 合成语音的格式，如无必要不建议修改
TTS_TYPE="" # 合成语音的引擎，可选sva-bv2,gsv,sbv2,sva-vits,sbv2api,aivis（需要角色适配）
## 语音合成 END

## 实验性功能 BEGIN # 配置实验性功能
ENABLE_EMOTION_CLASSIFIER=true # 启用/禁用情绪分类器（警告：同时关闭RAG功能后可大幅减少冷启动时间，但表情显示可能不正常）
ENABLE_DIRECT_EMOTION_CLASSIFIER=true # 是否在原有情绪可用时直接使用原标签
ENABLE_TRANSLATE=true # 是否启用日语翻译功能，而不依赖于LLM的日语（需要新版人物，默认钦灵已适配）
TRANSLATE_STREAM=true # 是否启用翻译流式处理（建议开启）
OPEN_FRONTEND_APP=true # 是否在启动后端时自动打开前端应用 
USE_STREAM=true # 是否使用LLM流式生成
VOICE_CHECK=false # 是否启用语音合成检查
## 实验性功能 END

## 日程功能 BEGIN # 配置日程提醒功能（测试版）
ENABLE_SCHEDULE=false # 是否启用日程功能（包括提醒、随机聊天和窥屏功能）
## 日程功能 END
# 开发者设置 END
