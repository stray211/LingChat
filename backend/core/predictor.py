from transformers import BertTokenizer, BertForSequenceClassification
import torch
import os
import json
from pathlib import Path
from .logger import logger, TermColors

class EmotionClassifier:
    def __init__(self, model_path=None):
        """åŠ è½½æƒ…ç»ªåˆ†ç±»æ¨¡å‹"""
    
        try:
            model_path = model_path or os.environ.get("EMOTION_MODEL_PATH", "./emotion_model_18emo")
            model_path = Path(model_path).resolve()
            self.tokenizer = BertTokenizer.from_pretrained(model_path, local_files_only=True)
            self.model = BertForSequenceClassification.from_pretrained(model_path)
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.model.to(self.device)
            
            config_path = os.path.join(model_path, "label_mapping.json")
            with open(config_path, "r", encoding='utf-8') as f: 
                label_config = json.load(f)
            self.id2label = label_config["id2label"]
            self.label2id = label_config["label2id"]
            
            self._log_label_mapping()
            self._log_emotion_model_status(True, f"å·²æˆåŠŸåŠ è½½æƒ…ç»ªåˆ†ç±»æ¨¡å‹: {model_path.name}")
        except Exception as e:
            self._log_emotion_model_status(False, f"åŠ è½½æƒ…ç»ªåˆ†ç±»æ¨¡å‹å¤±è´¥: {e}")
            self.id2label = {}
            self.label2id = {}

    def _log_label_mapping(self):
        """è®°å½•æ ‡ç­¾æ˜ å°„å…³ç³»"""
        logger.debug("\nåŠ è½½çš„æ ‡ç­¾æ˜ å°„å…³ç³»:")
        for id, label in self.id2label.items():
            logger.debug(f"{id}: {label}")

    def _log_emotion_model_status(self, is_success: bool, details: str = None):
        """æƒ…ç»ªæ¨¡å‹åŠ è½½çŠ¶æ€è®°å½•ï¼Œå…¼å®¹æ—§æ¥å£"""
        status = "æƒ…ç»ªåˆ†ç±»æ¨¡å‹åŠ è½½æ­£å¸¸" if is_success else "æƒ…ç»ªåˆ†ç±»æ¨¡å‹åŠ è½½å¼‚å¸¸"
        status_color = TermColors.GREEN if is_success else TermColors.RED
        status_symbol = "âˆš" if is_success else "Ã—"
        
        if details:
            if is_success:
                logger.info(f"{status_color}{status_symbol}{TermColors.RESET} {status} - {details}")
            else:
                logger.error(f"{status_color}{status_symbol}{TermColors.RESET} {status} - {details}")
        else:
            if is_success:
                logger.info(f"{status_color}{status_symbol}{TermColors.RESET} {status}")
            else:
                logger.error(f"{status_color}{status_symbol}{TermColors.RESET} {status}")

    def predict(self, text, confidence_threshold=0.08):
        """é¢„æµ‹æ–‡æœ¬æƒ…ç»ªï¼ˆå¸¦ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰"""
        try:
            inputs = self.tokenizer(
                text, 
                truncation=True, 
                max_length=128, 
                return_tensors="pt"
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = torch.softmax(outputs.logits, dim=1)
            
            pred_prob, pred_id = torch.max(probs, dim=1)
            pred_prob = pred_prob.item()
            pred_id = pred_id.item()
            
            top3 = self._get_top3(probs)
            
            if pred_prob < confidence_threshold:
                logger.debug(f"æƒ…ç»ªè¯†åˆ«ç½®ä¿¡åº¦ä½: {text} -> ä¸ç¡®å®š ({pred_prob:.2%})")
                return {
                    "label": "ä¸ç¡®å®š",
                    "confidence": pred_prob,
                    "top3": top3,
                    "warning": f"ç½®ä¿¡åº¦ä½äºé˜ˆå€¼({confidence_threshold:.0%})"
                }
            
            label = self.id2label.get(str(pred_id), "")
            logger.debug(f"æƒ…ç»ªè¯†åˆ«: {text} -> {label} ({pred_prob:.2%})")
            return {
                "label": label,
                "confidence": pred_prob,
                "top3": top3
            }
        except Exception as e:
            logger.error(f"æƒ…ç»ªé¢„æµ‹é”™è¯¯: {e}")
            return {
                "label": "",
                "confidence": 0.0,
                "top3": [],
                "error": str(e)
            }

    def _get_top3(self, probs):
        """è·å–æ¦‚ç‡æœ€é«˜çš„3ä¸ªç»“æœ"""
        top3_probs, top3_ids = torch.topk(probs, 3)
        return [
            {
                "label": self.id2label.get(str(idx.item()), ""),
                "probability": prob.item()
            }
            for prob, idx in zip(top3_probs[0], top3_ids[0])
        ]

def main():
    print("ã€æƒ…ç»ªåˆ†ç±»å™¨ã€‘")
    print("="*40)
    
    try:
        classifier = EmotionClassifier()
        print("\næ¨¡å‹åŠ è½½æˆåŠŸï¼è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†æï¼Œè¾“å…¥ ':q' é€€å‡º")
    except Exception as e:
        print(f"\næ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥ï¼š")
        print("1. æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨")
        print("2. ç›®å½•æ˜¯å¦åŒ…å« label_mapping.json æ–‡ä»¶")
        return
    
    while True:
        try:
            text = input("\nè¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
            
            if text.lower() in [':q', ':quit', 'exit']:
                print("\né€€å‡ºç¨‹åº")
                break
                
            if not text:
                print("è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼")
                continue
                
            result = classifier.predict(text)
            print("\n" + "="*30)
            print(f"ğŸ“ æ–‡æœ¬: {text}")
            
            if "warning" in result:
                print(f"âš ï¸ {result['warning']}")
            
            print(f"ğŸ¯ ä¸»æƒ…ç»ª: {result['label']} (ç½®ä¿¡åº¦: {result['confidence']:.2%})")
            
            if result['label'] != "ä¸ç¡®å®š":
                print("\nå…¶ä»–å¯èƒ½æƒ…ç»ª:")
                for i, item in enumerate(result["top3"][1:], 1):
                    print(f"{i}. {item['label']}: {item['probability']:.2%}")
            
            print("="*30)
            
        except KeyboardInterrupt:
            print("\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº...")
            break
        except Exception as e:
            print(f"\nâŒ é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
